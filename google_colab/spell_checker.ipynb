{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sukhman723/my_projects/blob/main/google_colab/spell_checker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bbhnov6SmsZp",
        "outputId": "e935280d-7bf4-40ed-e662-4021a40c3a2f"
      },
      "id": "Bbhnov6SmsZp",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9o7CDSklRFK"
      },
      "source": [
        "## Outline\n",
        "- [0. Overview](#0)\n",
        "- [1. Data Preprocessing](#1)\n",
        "- [2. String Manipulation](#2)\n",
        "- [3. Combining the edits](#3)\n",
        "- [4. Minimum Edit Distance](#4)\n",
        "- [5. Backtrace (Optional)](#5)"
      ],
      "id": "l9o7CDSklRFK"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7472YtMlRFM"
      },
      "source": [
        "<a name='0'></a>\n",
        "## 0. Overview\n",
        "\n",
        "You use autocorrect every day on your cell phone and computer. In this assignment, you will explore what really goes on behind the scenes. Of course, the model you are about to implement is not identical to the one used in your phone, but it is still quite good. \n",
        "\n",
        "By completing this assignment you will learn how to: \n",
        "\n",
        "- Get a word count given a corpus\n",
        "- Get a word probability in the corpus \n",
        "- Manipulate strings \n",
        "- Filter strings \n",
        "- Implement Minimum edit distance to compare strings and to help find the optimal path for the edits. \n",
        "- Understand how dynamic programming works\n",
        "\n",
        "\n",
        "Similar systems are used everywhere. \n",
        "- For example, if you type in the word **\"I am lerningg\"**, chances are very high that you meant to write **\"learning\"**, as shown in **Figure 1**. "
      ],
      "id": "g7472YtMlRFM"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTKpjXl-lRFN"
      },
      "source": [
        "<div style=\"width:image width px; font-size:100%; text-align:center;\"><img src='images/auto-correct.png' alt=\"alternate text\" width=\"width\" height=\"height\" style=\"width:300px;height:250px;\" /> Figure 1 </div>"
      ],
      "id": "eTKpjXl-lRFN"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wedOhJgTlRFQ"
      },
      "source": [
        "<a name='1'></a>\n",
        "# Part 1: Data Preprocessing "
      ],
      "id": "wedOhJgTlRFQ"
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/Code_files_and_data/"
      ],
      "metadata": {
        "id": "l546XyPcm8Xf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f6b27fc-2cc5-40e4-fc9f-702fe1dd1fb7"
      },
      "id": "l546XyPcm8Xf",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Code_files_and_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "BWoVBM4flRFS"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import itertools\n"
      ],
      "id": "BWoVBM4flRFS"
    },
    {
      "cell_type": "code",
      "source": [
        "!ls data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtBNY8M3nTSt",
        "outputId": "047a35ad-32e9-49da-f104-868c943594eb"
      },
      "id": "gtBNY8M3nTSt",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "en_embeddings.p  en-fr.train.txt    fr_embeddings.p\n",
            "en-fr.test.txt\t en_US.twitter.txt  shakespeare.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "hmkkUICylRFZ"
      },
      "outputs": [],
      "source": [
        "# UNQ_C1 GRADED FUNCTION: process_data\n",
        "def process_data(file_name):\n",
        "    \"\"\"\n",
        "    Input: \n",
        "        A file_name which is found in your current directory. You just have to read it in. \n",
        "    Output: \n",
        "        words: a list containing all the words in the corpus (text file you read) in lower case. \n",
        "    \"\"\"\n",
        "    words = [] # return this variable correctly\n",
        "\n",
        "    ### START CODE HERE ### \n",
        "    \n",
        "    #Open the file, read its contents into a string variable\n",
        "    with open(file_name, 'r') as file:\n",
        "        data = file.read()\n",
        "    \n",
        "    # convert all letters to lower case\n",
        "    data = data.lower()\n",
        "    words = re.findall(r\"\\w+\", data)\n",
        "    #Convert every word to lower case and return them in a list.\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return words"
      ],
      "id": "hmkkUICylRFZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LSwC4tnTlRFa"
      },
      "outputs": [],
      "source": [
        "with open('data/shakespeare.txt', 'r') as file:\n",
        "    data = file.read()\n",
        "    \n",
        "data = data.lower()\n",
        "words = re.findall(r\"\\w+\", data)\n",
        "words       "
      ],
      "id": "LSwC4tnTlRFa"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTI_hr8wlRFb",
        "outputId": "ae670621-d1ef-46d8-9534-916b1b8800b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The first ten words in the text are: \n",
            "['o', 'for', 'a', 'muse', 'of', 'fire', 'that', 'would', 'ascend', 'the']\n",
            "There are 6116 unique words in the vocabulary.\n"
          ]
        }
      ],
      "source": [
        "#DO NOT MODIFY THIS CELL\n",
        "word_l = process_data('data/shakespeare.txt')\n",
        "vocab = set(word_l)  # this will be your new vocabulary\n",
        "print(f\"The first ten words in the text are: \\n{word_l[0:10]}\")\n",
        "print(f\"There are {len(vocab)} unique words in the vocabulary.\")"
      ],
      "id": "BTI_hr8wlRFb"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "f-KPZUAGlRFe"
      },
      "outputs": [],
      "source": [
        "# UNIT TEST COMMENT: Candidate for Table Driven Tests\n",
        "# UNQ_C2 GRADED FUNCTION: get_count\n",
        "def get_count(word_l):\n",
        "    '''\n",
        "    Input:\n",
        "        word_l: a set of words representing the corpus. \n",
        "    Output:\n",
        "        word_count_dict: The wordcount dictionary where key is the word and value is its frequency.\n",
        "    '''\n",
        "    \n",
        "    word_count_dict = {}  # fill this with word counts\n",
        "    ### START CODE HERE \n",
        "    word_count_dict = Counter(word_l)\n",
        "    ### END CODE HERE ### \n",
        "    return word_count_dict"
      ],
      "id": "f-KPZUAGlRFe"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cjcznxt5lRFe",
        "outputId": "8506f7b6-3d87-43ea-d746-3504c67a342a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 6116 key values pairs\n",
            "The count for the word 'thee' is 240\n"
          ]
        }
      ],
      "source": [
        "#DO NOT MODIFY THIS CELL\n",
        "word_count_dict = get_count(word_l)\n",
        "print(f\"There are {len(word_count_dict)} key values pairs\")\n",
        "print(f\"The count for the word 'thee' is {word_count_dict.get('thee',0)}\")"
      ],
      "id": "Cjcznxt5lRFe"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "2RyCdv_qlRFh"
      },
      "outputs": [],
      "source": [
        "# UNQ_C3 GRADED FUNCTION: get_probs\n",
        "def get_probs(word_count_dict):\n",
        "    '''\n",
        "    Input:\n",
        "        word_count_dict: The wordcount dictionary where key is the word and value is its frequency.\n",
        "    Output:\n",
        "        probs: A dictionary where keys are the words and the values are the probability that a word will occur. \n",
        "    '''\n",
        "    probs = {}  # return this variable correctly\n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "    \n",
        "    # get the total count of words for all words in the dictionary\n",
        "    total_count = sum(word_count_dict.values())\n",
        "    for p, v in word_count_dict.items():\n",
        "        probs[p] = v/total_count\n",
        "    ### END CODE HERE ###\n",
        "    return probs"
      ],
      "id": "2RyCdv_qlRFh"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Utu33FJwlRFh",
        "outputId": "1877d768-1901-43fb-cda8-dec5603a0692"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of probs is 6116\n",
            "P('thee') is 0.0045\n"
          ]
        }
      ],
      "source": [
        "#DO NOT MODIFY THIS CELL\n",
        "probs = get_probs(word_count_dict)\n",
        "print(f\"Length of probs is {len(probs)}\")\n",
        "print(f\"P('thee') is {probs['thee']:.4f}\")"
      ],
      "id": "Utu33FJwlRFh"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "SFPH2qbnlRFo"
      },
      "outputs": [],
      "source": [
        "# UNIT TEST COMMENT: Candidate for Table Driven Tests\n",
        "# UNQ_C4 GRADED FUNCTION: deletes\n",
        "def delete_letter(word, verbose=False):\n",
        "    '''\n",
        "    Input:\n",
        "        word: the string/word for which you will generate all possible words \n",
        "                in the vocabulary which have 1 missing character\n",
        "    Output:\n",
        "        delete_l: a list of all possible strings obtained by deleting 1 character from word\n",
        "    '''\n",
        "    \n",
        "    delete_l = []\n",
        "    split_l = []\n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "    split_l = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
        "    delete_l = [v_1 + v_2[1:] for v_1, v_2 in split_l if v_2]\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    if verbose: print(f\"input word {word}, \\nsplit_l = {split_l}, \\ndelete_l = {delete_l}\")\n",
        "\n",
        "    return  delete_l"
      ],
      "id": "SFPH2qbnlRFo"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3OgDOGRlRFp",
        "outputId": "7b7f2205-f445-4b2a-cdef-e6397e657a55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input word cans, \n",
            "split_l = [('', 'cans'), ('c', 'ans'), ('ca', 'ns'), ('can', 's'), ('cans', '')], \n",
            "delete_l = ['ans', 'cns', 'cas', 'can']\n"
          ]
        }
      ],
      "source": [
        "delete_word_l = delete_letter(word=\"cans\",\n",
        "                        verbose=True)"
      ],
      "id": "l3OgDOGRlRFp"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGJePyGglRFr",
        "outputId": "762ff46e-521b-400d-c6d7-afbaded9c430"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of outputs of delete_letter('at') is 2\n"
          ]
        }
      ],
      "source": [
        "# test # 2\n",
        "print(f\"Number of outputs of delete_letter('at') is {len(delete_letter('at'))}\")"
      ],
      "id": "iGJePyGglRFr"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "lines_to_end_of_cell_marker": 2,
        "id": "-sUkJZj7lRFu"
      },
      "outputs": [],
      "source": [
        "# UNIT TEST COMMENT: Candidate for Table Driven Tests\n",
        "# UNQ_C5 GRADED FUNCTION: switches\n",
        "def switch_letter(word, verbose=False):\n",
        "    '''\n",
        "    Input:\n",
        "        word: input string\n",
        "     Output:\n",
        "        switches: a list of all possible strings with one adjacent charater switched\n",
        "    ''' \n",
        "    \n",
        "    switch_l = []\n",
        "    split_l = []\n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "    split_l = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
        "    switch_l = [l + r[1] + r.replace(r[1], '') for l, r in split_l if len(r) >= 2]\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    if verbose: print(f\"Input word = {word} \\nsplit_l = {split_l} \\nswitch_l = {switch_l}\") \n",
        "    \n",
        "    return switch_l"
      ],
      "id": "-sUkJZj7lRFu"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "jpB1P3R4lRFv",
        "outputId": "f00621c7-19f6-49d7-e916-9426ba94a284"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'acns'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "word = 'cans'\n",
        "word[1] + word.replace(word[1], '')"
      ],
      "id": "jpB1P3R4lRFv"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWUCBVaylRFv",
        "outputId": "a96e72f9-39ef-4a46-8729-9e236b3dcbc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input word = eta \n",
            "split_l = [('', 'eta'), ('e', 'ta'), ('et', 'a'), ('eta', '')] \n",
            "switch_l = ['tea', 'eat']\n"
          ]
        }
      ],
      "source": [
        "switch_word_l = switch_letter(word=\"eta\",\n",
        "                         verbose=True)"
      ],
      "id": "UWUCBVaylRFv"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNXSOz16lRFx",
        "outputId": "a3c3d1ed-2e72-49f0-9a69-3eb80200d557"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of outputs of switch_letter('at') is 1\n"
          ]
        }
      ],
      "source": [
        "# test # 2\n",
        "print(f\"Number of outputs of switch_letter('at') is {len(switch_letter('at'))}\")"
      ],
      "id": "TNXSOz16lRFx"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "EHFI_wNmlRFy"
      },
      "outputs": [],
      "source": [
        "# UNIT TEST COMMENT: Candidate for Table Driven Tests\n",
        "# UNQ_C6 GRADED FUNCTION: replaces\n",
        "def replace_letter(word, verbose=False):\n",
        "    '''\n",
        "    Input:\n",
        "        word: the input string/word \n",
        "    Output:\n",
        "        replaces: a list of all possible strings where we replaced one letter from the original word. \n",
        "    ''' \n",
        "    \n",
        "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
        "    \n",
        "    replace_l = []\n",
        "    split_l = []\n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "    split_l = [(word[:i], word[i:]) for i in range(len(word))]\n",
        "    replace_set = [l + r.replace(r[0], letter) for l, r in split_l for letter in letters if letter != r[0]]\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    # turn the set back into a list and sort it, for easier viewing\n",
        "    replace_l = sorted(list(set(replace_set)))\n",
        "    \n",
        "    if verbose: print(f\"Input word = {word} \\nsplit_l = {split_l} \\nreplace_l {replace_l}\")   \n",
        "    \n",
        "    return replace_l"
      ],
      "id": "EHFI_wNmlRFy"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G56N16PLlRFz",
        "outputId": "84c4a11f-fbec-43ca-a65e-614d21218bce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input word = can \n",
            "split_l = [('', 'can'), ('c', 'an'), ('ca', 'n')] \n",
            "replace_l ['aan', 'ban', 'caa', 'cab', 'cac', 'cad', 'cae', 'caf', 'cag', 'cah', 'cai', 'caj', 'cak', 'cal', 'cam', 'cao', 'cap', 'caq', 'car', 'cas', 'cat', 'cau', 'cav', 'caw', 'cax', 'cay', 'caz', 'cbn', 'ccn', 'cdn', 'cen', 'cfn', 'cgn', 'chn', 'cin', 'cjn', 'ckn', 'cln', 'cmn', 'cnn', 'con', 'cpn', 'cqn', 'crn', 'csn', 'ctn', 'cun', 'cvn', 'cwn', 'cxn', 'cyn', 'czn', 'dan', 'ean', 'fan', 'gan', 'han', 'ian', 'jan', 'kan', 'lan', 'man', 'nan', 'oan', 'pan', 'qan', 'ran', 'san', 'tan', 'uan', 'van', 'wan', 'xan', 'yan', 'zan']\n"
          ]
        }
      ],
      "source": [
        "replace_l = replace_letter(word='can',\n",
        "                              verbose=True)"
      ],
      "id": "G56N16PLlRFz"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxBc5a0_lRF1",
        "outputId": "2181f47b-8999-4867-80de-04ad6dc4e1c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of outputs of replace_letter('at') is 50\n"
          ]
        }
      ],
      "source": [
        "# test # 2\n",
        "print(f\"Number of outputs of replace_letter('at') is {len(replace_letter('at'))}\")"
      ],
      "id": "zxBc5a0_lRF1"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "jWBO4RA8lRF4"
      },
      "outputs": [],
      "source": [
        "# UNIT TEST COMMENT: Candidate for Table Driven Tests\n",
        "# UNQ_C7 GRADED FUNCTION: inserts\n",
        "def insert_letter(word, verbose=False):\n",
        "    '''\n",
        "    Input:\n",
        "        word: the input string/word \n",
        "    Output:\n",
        "        inserts: a set of all possible strings with one new letter inserted at every offset\n",
        "    ''' \n",
        "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
        "    insert_l = []\n",
        "    split_l = []\n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "    split_l = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
        "    insert_l = [l + letter + r for l, r in split_l for letter in letters]\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    if verbose: print(f\"Input word {word} \\nsplit_l = {split_l} \\ninsert_l = {insert_l}\")\n",
        "    \n",
        "    return insert_l"
      ],
      "id": "jWBO4RA8lRF4"
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TY9N94iQlRF4",
        "outputId": "965d7df8-e71d-4c28-f9b1-b8f606ad3a06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input word at \n",
            "split_l = [('', 'at'), ('a', 't'), ('at', '')] \n",
            "insert_l = ['aat', 'bat', 'cat', 'dat', 'eat', 'fat', 'gat', 'hat', 'iat', 'jat', 'kat', 'lat', 'mat', 'nat', 'oat', 'pat', 'qat', 'rat', 'sat', 'tat', 'uat', 'vat', 'wat', 'xat', 'yat', 'zat', 'aat', 'abt', 'act', 'adt', 'aet', 'aft', 'agt', 'aht', 'ait', 'ajt', 'akt', 'alt', 'amt', 'ant', 'aot', 'apt', 'aqt', 'art', 'ast', 'att', 'aut', 'avt', 'awt', 'axt', 'ayt', 'azt', 'ata', 'atb', 'atc', 'atd', 'ate', 'atf', 'atg', 'ath', 'ati', 'atj', 'atk', 'atl', 'atm', 'atn', 'ato', 'atp', 'atq', 'atr', 'ats', 'att', 'atu', 'atv', 'atw', 'atx', 'aty', 'atz']\n",
            "Number of strings output by insert_letter('at') is 78\n"
          ]
        }
      ],
      "source": [
        "insert_l = insert_letter('at', True)\n",
        "print(f\"Number of strings output by insert_letter('at') is {len(insert_l)}\")"
      ],
      "id": "TY9N94iQlRF4"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "6NqNLWPSlRF7"
      },
      "outputs": [],
      "source": [
        "# UNIT TEST COMMENT: Candidate for Table Driven Tests\n",
        "# UNQ_C8 GRADED FUNCTION: edit_one_letter\n",
        "def edit_one_letter(word, allow_switches = True):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        word: the string/word for which we will generate all possible wordsthat are one edit away.\n",
        "    Output:\n",
        "        edit_one_set: a set of words with one possible edit. Please return a set. and not a list.\n",
        "    \"\"\"\n",
        "    \n",
        "    edit_one_set = set()\n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "    l_i = insert_letter(word)\n",
        "    l_d = delete_letter(word)\n",
        "    l_r = replace_letter(word)\n",
        "    if allow_switches:\n",
        "        l_s = switch_letter(word)\n",
        "        edit_one_set = set(l_i + l_d + l_r + l_s)\n",
        "    else:\n",
        "        edit_one_set = set(l_i + l_d + l_r)\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    # return this as a set and not a list\n",
        "    return set(edit_one_set)"
      ],
      "id": "6NqNLWPSlRF7"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIonr5w1lRF7",
        "outputId": "12b4c399-8da7-41bb-c427-8f725270bdcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input word at \n",
            "edit_one_l \n",
            "['a', 'aa', 'aat', 'ab', 'abt', 'ac', 'act', 'ad', 'adt', 'ae', 'aet', 'af', 'aft', 'ag', 'agt', 'ah', 'aht', 'ai', 'ait', 'aj', 'ajt', 'ak', 'akt', 'al', 'alt', 'am', 'amt', 'an', 'ant', 'ao', 'aot', 'ap', 'apt', 'aq', 'aqt', 'ar', 'art', 'as', 'ast', 'ata', 'atb', 'atc', 'atd', 'ate', 'atf', 'atg', 'ath', 'ati', 'atj', 'atk', 'atl', 'atm', 'atn', 'ato', 'atp', 'atq', 'atr', 'ats', 'att', 'atu', 'atv', 'atw', 'atx', 'aty', 'atz', 'au', 'aut', 'av', 'avt', 'aw', 'awt', 'ax', 'axt', 'ay', 'ayt', 'az', 'azt', 'bat', 'bt', 'cat', 'ct', 'dat', 'dt', 'eat', 'et', 'fat', 'ft', 'gat', 'gt', 'hat', 'ht', 'iat', 'it', 'jat', 'jt', 'kat', 'kt', 'lat', 'lt', 'mat', 'mt', 'nat', 'nt', 'oat', 'ot', 'pat', 'pt', 'qat', 'qt', 'rat', 'rt', 'sat', 'st', 't', 'ta', 'tat', 'tt', 'uat', 'ut', 'vat', 'vt', 'wat', 'wt', 'xat', 'xt', 'yat', 'yt', 'zat', 'zt']\n",
            "\n",
            "The type of the returned object should be a set <class 'set'>\n",
            "Number of outputs from edit_one_letter('at') is 129\n"
          ]
        }
      ],
      "source": [
        "tmp_word = \"at\"\n",
        "tmp_edit_one_set = edit_one_letter(tmp_word)\n",
        "# turn this into a list to sort it, in order to view it\n",
        "tmp_edit_one_l = sorted(list(tmp_edit_one_set))\n",
        "\n",
        "print(f\"input word {tmp_word} \\nedit_one_l \\n{tmp_edit_one_l}\\n\")\n",
        "print(f\"The type of the returned object should be a set {type(tmp_edit_one_set)}\")\n",
        "print(f\"Number of outputs from edit_one_letter('at') is {len(edit_one_letter('at'))}\")"
      ],
      "id": "EIonr5w1lRF7"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "qIqrV_YGlRF-"
      },
      "outputs": [],
      "source": [
        "# UNIT TEST COMMENT: Candidate for Table Driven Tests\n",
        "# UNQ_C9 GRADED FUNCTION: edit_two_letters\n",
        "def edit_two_letters(word, allow_switches = True):\n",
        "    '''\n",
        "    Input:\n",
        "        word: the input string/word \n",
        "    Output:\n",
        "        edit_two_set: a set of strings with all possible two edits\n",
        "    '''\n",
        "    \n",
        "    edit_two_set = set()\n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "    l_i = set()\n",
        "    l_d = set()\n",
        "    l_r = set()\n",
        "    l_s = set()\n",
        "    words = edit_one_letter(word)\n",
        "    for word in words:\n",
        "        edit_two_set.update(set(edit_one_letter(word)))\n",
        "    '''\n",
        "    for word in words:\n",
        "        l_i.update(insert_letter(word))\n",
        "        l_d.update(delete_letter(word))\n",
        "        l_r.update(replace_letter(word))\n",
        "        if allow_switches:\n",
        "            l_s.update(switch_letter(word))\n",
        "    edit_two_set = edit_two_set.union(l_i, l_d, l_r, l_s)\n",
        "            \n",
        "    ### END CODE HERE ###\n",
        "    '''\n",
        "    \n",
        "    # return this as a set instead of a list\n",
        "    return set(edit_two_set)"
      ],
      "id": "qIqrV_YGlRF-"
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUoULfEYlRF-",
        "outputId": "ee9078ea-6424-4c08-8452-7a54c523102f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of strings with edit distance of two: 2654\n",
            "First 10 strings ['', 'a', 'aa', 'aaa', 'aab', 'aac', 'aad', 'aae', 'aaf', 'aag']\n",
            "Last 10 strings ['zv', 'zva', 'zw', 'zwa', 'zx', 'zxa', 'zy', 'zya', 'zz', 'zza']\n",
            "The data type of the returned object should be a set <class 'set'>\n",
            "Number of strings that are 2 edit distances from 'at' is 7154\n"
          ]
        }
      ],
      "source": [
        "tmp_edit_two_set = edit_two_letters(\"a\")\n",
        "tmp_edit_two_l = sorted(list(tmp_edit_two_set))\n",
        "print(f\"Number of strings with edit distance of two: {len(tmp_edit_two_l)}\")\n",
        "print(f\"First 10 strings {tmp_edit_two_l[:10]}\")\n",
        "print(f\"Last 10 strings {tmp_edit_two_l[-10:]}\")\n",
        "print(f\"The data type of the returned object should be a set {type(tmp_edit_two_set)}\")\n",
        "print(f\"Number of strings that are 2 edit distances from 'at' is {len(edit_two_letters('at'))}\")"
      ],
      "id": "tUoULfEYlRF-"
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFj4tJ5nlRGA",
        "outputId": "85257aed-d4d4-4466-85ea-5182ebc6d2aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n",
            "['a', 'b']\n",
            "['Most', 'Likely']\n",
            "['least', 'of', 'all']\n"
          ]
        }
      ],
      "source": [
        "# example of logical operation on lists or sets\n",
        "print( [] and [\"a\",\"b\"] )\n",
        "print( [] or [\"a\",\"b\"] )\n",
        "#example of Short circuit behavior\n",
        "val1 =  [\"Most\",\"Likely\"] or [\"Less\",\"so\"] or [\"least\",\"of\",\"all\"]  # selects first, does not evalute remainder\n",
        "print(val1)\n",
        "val2 =  [] or [] or [\"least\",\"of\",\"all\"] # continues evaluation until there is a non-empty list\n",
        "print(val2)"
      ],
      "id": "XFj4tJ5nlRGA"
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "YHytn0DglRGC"
      },
      "outputs": [],
      "source": [
        "# UNIT TEST COMMENT: Candidate for Table Driven Tests\n",
        "# UNQ_C10 GRADED FUNCTION: get_corrections\n",
        "def get_corrections(word, probs, vocab, n=2, verbose = False):\n",
        "    '''\n",
        "    Input: \n",
        "        word: a user entered string to check for suggestions\n",
        "        probs: a dictionary that maps each word to its probability in the corpus\n",
        "        vocab: a set containing all the vocabulary\n",
        "        n: number of possible word corrections you want returned in the dictionary\n",
        "    Output: \n",
        "        n_best: a list of tuples with the most probable n corrected words and their probabilities.\n",
        "    '''\n",
        "    \n",
        "    suggestions = []\n",
        "    n_best = []\n",
        "    N = []\n",
        "    ### START CODE HERE ###\n",
        "    #Step 1: create suggestions as described above    \n",
        "    if word in vocab:\n",
        "        suggestions = word\n",
        "        print('word in vocab')\n",
        "    elif edit_one_letter(word).intersection(vocab):\n",
        "        print('first_edit_distance')\n",
        "        suggestions = edit_one_letter(word).intersection(vocab)\n",
        "    elif edit_two_letters(word).intersection(vocab):\n",
        "        print('second_edit_distance')\n",
        "        suggestions = edit_two_letters(word).intersection(vocab)\n",
        "    else:\n",
        "        suggestions = word\n",
        "    #Step 2: determine probability of suggestions\n",
        "    for word_ in suggestions:\n",
        "        try:\n",
        "          N.append((word_, probs[word_]))\n",
        "        except:\n",
        "          print('Sorry did not found ideal suggestions')\n",
        "    #Step 3: Get all your best words and return the most probable top n_suggested words as n_best\n",
        "    \n",
        "    n_best = sorted(N)\n",
        "    n_best = n_best[:n + 1]\n",
        "    \n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    if verbose: print(\"entered word = \", word, \"\\nsuggestions = \", suggestions)\n",
        "\n",
        "    return n_best"
      ],
      "id": "YHytn0DglRGC"
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "YQBcwbQNlRGE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3647a8dd-0603-4632-c2ce-02b6e1cd4898"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "second_edit_distance\n",
            "entered word =  wasteete \n",
            "suggestions =  {'wastes', 'waste', 'wasted', 'wast'}\n",
            "word 0: wast, probability 0.000056\n",
            "word 1: waste, probability 0.000131\n",
            "word 2: wasted, probability 0.000019\n",
            "data type of corrections <class 'list'>\n"
          ]
        }
      ],
      "source": [
        "# Test your implementation - feel free to try other words in my word\n",
        "my_word = 'wasteete' \n",
        "tmp_corrections = get_corrections(my_word, probs, vocab, 2, verbose=True) # keep verbose=True\n",
        "for i, word_prob in enumerate(tmp_corrections):\n",
        "    print(f\"word {i}: {word_prob[0]}, probability {word_prob[1]:.6f}\")\n",
        "\n",
        "# CODE REVIEW COMMENT: using \"tmp_corrections\" insteads of \"cors\". \"cors\" is not defined\n",
        "print(f\"data type of corrections {type(tmp_corrections)}\")"
      ],
      "id": "YQBcwbQNlRGE"
    }
  ],
  "metadata": {
    "jupytext": {
      "encoding": "# -*- coding: utf-8 -*-"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}